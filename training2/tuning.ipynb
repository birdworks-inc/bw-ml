{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290a8b6-a243-4890-81f1-d6035e1892cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for manifest_line in output_manifest_json:\n",
    "    # 画像のラベリング結果の読み込み\n",
    "    manifest_dict = json.loads(manifest_line)\n",
    "    print(manifest_dict['source-ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4f15c-ad3d-4b43-a6b1-50dc7741eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 からマニフェストファイルをLocal（manifestフォルダ）へダウンロード\n",
    "LOCAL_MANIFEST_DIR = \"./training-manifest/\"\n",
    "BASE_PREFIX = \"kinotake/images\"\n",
    "GT_JOB_NAME = \"kinotake-user1\"\n",
    "sagemaker.session.Session().download_data(LOCAL_MANIFEST_DIR, key_prefix=f'{BASE_PREFIX}/{GT_JOB_NAME}/manifests/output/output.manifest',bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eecd13-5997-4e70-9b90-eafdfeff660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 からLocalへラベリング済みデータのダウンロード\n",
    "TRAIN_RAWIMAGE_DIR = './training-train_raw_images/'\n",
    "import shutil\n",
    "shutil.rmtree(TRAIN_RAWIMAGE_DIR)\n",
    "os.mkdir(TRAIN_RAWIMAGE_DIR)\n",
    "\n",
    "# ラベリング結果をテキストとして読み込む\n",
    "with open(f'{LOCAL_MANIFEST_DIR}/output.manifest','r') as f:\n",
    "    manifest_line_list = f.readlines()\n",
    "\n",
    "for manifest_line in manifest_line_list:\n",
    "    # 画像のラベリング結果の読み込み\n",
    "    manifest_dict = json.loads(manifest_line)\n",
    "    filename = manifest_dict['source-ref'].split('/')[-1]\n",
    "    print(filename)\n",
    "    sagemaker.session.Session().download_data(TRAIN_RAWIMAGE_DIR, key_prefix=f'{BASE_PREFIX}/{filename}',bucket=BUCKET_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35100abd-d24d-4455-a5f9-d4235f6828ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロップした画像にきのこの山やたけのこの里が映っている場合、\n",
    "# クロップした後のきのこの山やたけのこの里が1/4以下かどうかを判定するヘルパー関数\n",
    "\n",
    "def fix_bbox(l,t,r,b,w,h):\n",
    "    # 判定結果、NG なら False にする\n",
    "    judge = True\n",
    "    # ラベリング結果のクロップ補正後の値が負の値ならば 0 に、イメージサイズより大きければイメージサイズに補正する\n",
    "    fix_left = 0 if l < 0 else l\n",
    "    fix_top = 0 if t < 0 else t\n",
    "    fix_right = w if r > w else r\n",
    "    fix_bottom = h if b > h else b\n",
    "    # 領域外ならラベリング無しとする\n",
    "    if l > w or t > h or r < 0 or b <0:\n",
    "        judge=False\n",
    "    # 基の面積の1/4以下ならアノテーション無しとする\n",
    "    elif (r-l)*(b-t)/4 > (fix_right-fix_left)*(fix_bottom-fix_top):\n",
    "        judge=False\n",
    "    \n",
    "    return judge,(fix_left,fix_top,fix_right,fix_bottom)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664a503-1b64-403f-ae61-6d7a62d583d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_MANIFEST_PATH = \"kinotake/images/kinotake-user1/manifests/output/output.manifest\"\n",
    "# output_manifest_object = my_bucket.Object(OUTPUT_MANIFEST_PATH)\n",
    "# output_manifest_json = output_manifest_object.get()[\"Body\"].read().decode('utf-8').split()\n",
    "\n",
    "\n",
    "OUTPUT_PATH = \"kinotake/annotations.json\"\n",
    "OUTPUT_DIR = './training-train_random_crop_images/'\n",
    "shutil.rmtree(OUTPUT_DIR)\n",
    "os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "# ラベリング結果をテキストとして読み込む\n",
    "with open('manifest/output.manifest','r') as f:\n",
    "    manifest_line_list = f.readlines()\n",
    "\n",
    "# クロップサイズの定数\n",
    "IMAGE_SIZE_TUPLE=(512,512)\n",
    "\n",
    "# 結果のきのこの山やたけのこの里の位置情報を格納する辞書 \n",
    "annotation_dict = {\n",
    "    'images':[],\n",
    "    'annotations':[]\n",
    "}\n",
    "\n",
    "# 画像のファイル名に使う一意なシーケンス番号\n",
    "IMAGE_ID = 0\n",
    "\n",
    "# ラベリング結果の行数分ループする\n",
    "# ラベリング結果は 1 行につき 1 画像格納される\n",
    "for manifest_line in manifest_line_list:\n",
    "    # 画像のラベリング結果の読み込み\n",
    "    manifest_dict = json.loads(manifest_line)\n",
    "    # print(manifest_dict)\n",
    "    # 画像のファイル名取得(ラベリング結果に格納されている)\n",
    "    filename = manifest_dict['source-ref'].split('/')[-1]\n",
    "    annotation_list = manifest_dict['kinotake-user1']['annotations']\n",
    "    # 元画像のサイズを取得(ラベリング結果に格納されている)\n",
    "    image_size_tuple=(manifest_dict[GT_JOB_NAME]['image_size'][0]['width'],manifest_dict[GT_JOB_NAME]['image_size'][0]['height'])\n",
    "    # PIL で画像を開く\n",
    "    raw_img = Image.open(os.path.join(TRAIN_RAWIMAGE_DIR,filename))\n",
    "    # 20 回クロップする\n",
    "    for i in range(20):\n",
    "        # ループするかどうかのフラグ(画像にきのこの山やたけのこの里が 2 枚未満だったらクロップをやりなおし)\n",
    "        loop = True\n",
    "        while loop:\n",
    "            # クロップを行う左上の座標を設定\n",
    "            rand_x = np.random.randint(0,image_size_tuple[0]-IMAGE_SIZE_TUPLE[0])\n",
    "            rand_y = np.random.randint(0,image_size_tuple[1]-IMAGE_SIZE_TUPLE[1])\n",
    "            # クロップする\n",
    "            crop_img = raw_img.crop((\n",
    "                rand_x,\n",
    "                rand_y,\n",
    "                rand_x + IMAGE_SIZE_TUPLE[0],\n",
    "                rand_y + IMAGE_SIZE_TUPLE[1]\n",
    "            ))\n",
    "            # クロップ後のきのこの山やたけのこの里の位置を格納するリスト\n",
    "            annotation_list = []\n",
    "            # 元画像のラベリング結果をループ\n",
    "            for annotation in manifest_dict[GT_JOB_NAME]['annotations']:\n",
    "                # クロップした後のきのこの山やたけのこの里の座標に補正\n",
    "                left = annotation['left'] - rand_x\n",
    "                top = annotation['top'] - rand_y\n",
    "                right = annotation['left'] + annotation['width'] - rand_x\n",
    "                bottom = annotation['top'] + annotation['height'] - rand_y\n",
    "                # きのこの山やたけのこの里があるかどうかを判定\n",
    "                judge,(left,top,right,bottom) = fix_bbox(left,top,right,bottom,IMAGE_SIZE_TUPLE[0],IMAGE_SIZE_TUPLE[1])\n",
    "                if judge:\n",
    "                    # きのこの山やたけのこの里があったら位置とラベルを追加\n",
    "                    annotation_list.append(\n",
    "                        {\n",
    "                            'bbox':[left,top,right,bottom],\n",
    "                            'category_id':annotation['class_id']\n",
    "                        }\n",
    "                    )\n",
    "            # きのこの山やたけのこの里と数が2未満だったらクロップやり直し\n",
    "            if len(annotation_list) > 0:\n",
    "                loop = False\n",
    "        \n",
    "        # クロップしたら画像を保存する\n",
    "        save_file_name = f'{str(IMAGE_ID).zfill(5)}_{str(i).zfill(5)}_{filename}'.replace('jpg','png')\n",
    "        crop_img.save(os.path.join(OUTPUT_DIR,save_file_name))\n",
    "        \n",
    "        # 補正済ラベリング結果を出力用辞書に格納\n",
    "        annotation_dict['images'].append(\n",
    "            {\n",
    "                'file_name' : save_file_name,\n",
    "                'height' : IMAGE_SIZE_TUPLE[1],\n",
    "                'width' : IMAGE_SIZE_TUPLE[0],\n",
    "                'id' : IMAGE_ID\n",
    "            }\n",
    "        )\n",
    "        for annotation in annotation_list:                  \n",
    "            annotation_dict['annotations'].append(\n",
    "                {\n",
    "                    'image_id': IMAGE_ID,\n",
    "                    'bbox':annotation['bbox'],\n",
    "                    'category_id':annotation['category_id']\n",
    "                }\n",
    "            )\n",
    "        IMAGE_ID += 1\n",
    "    # # print(annotation_list)\n",
    "    # # ラベリング結果を出力用辞書に格納\n",
    "    # annotation_dict['images'].append(\n",
    "    #     {\n",
    "    #         'file_name' : filename,\n",
    "    #         'height' : manifest_dict['kinotake-user1']['image_size'][0]['height'],\n",
    "    #         'width' : manifest_dict['kinotake-user1']['image_size'][0]['width'],\n",
    "    #         'id' : IMAGE_ID\n",
    "    #     }\n",
    "    # )\n",
    "    # for annotation in annotation_list:\n",
    "    #     # 座標変換\n",
    "    #     left = annotation['left']\n",
    "    #     top = annotation['top']\n",
    "    #     right = annotation['left'] + annotation['width']\n",
    "    #     bottom = annotation['top'] + annotation['height']\n",
    "    #     # アノテーションを編集\n",
    "    #     annotation_dict['annotations'].append(\n",
    "    #         {\n",
    "    #             'image_id': IMAGE_ID,\n",
    "    #             'bbox': [left, top, right, bottom],\n",
    "    #             # 文字列へ変換し格納\n",
    "    #             # 'category_id': manifest_dict['kinotake-user1-metadata']['class-map'][str(annotation['class_id'])]\n",
    "    #             'category_id': annotation['class_id']\n",
    "    #         }\n",
    "    #     )\n",
    "    \n",
    "    # IMAGE_ID += 1\n",
    "    \n",
    "# ランダムクロップ補正後のラベリング結果を出力\n",
    "with open('annotations.json','wt') as f:\n",
    "    f.write(json.dumps(annotation_dict))        \n",
    "\n",
    "\n",
    "# 出力したディレクトリを prefix として使う\n",
    "prefix = OUTPUT_DIR[2:-1]\n",
    "\n",
    "# re-run 用の削除コマンド\n",
    "!aws s3 rm s3://{BUCKET_NAME}/{prefix} --recursive\n",
    "# ランダムクロップした画像をアップロード    \n",
    "image_s3_uri = sagemaker.session.Session().upload_data(OUTPUT_DIR,key_prefix=f'{prefix}/images')\n",
    "# ラベリング結果をアップロード\n",
    "annotatione_s3_uri = sagemaker.session.Session().upload_data('./annotations.json',key_prefix=prefix)\n",
    "# Fine-Tune で使う URI を出力\n",
    "paste_str = image_s3_uri.replace('/images','')\n",
    "print(f\"paste string to S3 bucket address：{paste_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b827af-5418-4a3c-b9cb-e8d04149de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力画像確認\n",
    "FILE_NAME = '00082_00002_32928BBF-99B8-4F05-ACB6-2599C9554A63_1_105_c.jpeg'\n",
    "INPUT_IMAGE_FILE = f'{OUTPUT_DIR}{FILE_NAME}'\n",
    "print(INPUT_IMAGE_FILE)\n",
    "# 推論対象の画像を開いて変数に格納\n",
    "with open(INPUT_IMAGE_FILE, 'rb') as f:\n",
    "    img_bin = f.read()\n",
    "\n",
    "# ラベリング結果(json)を読み込む\n",
    "with open('annotations.json') as f:\n",
    "    annotations_json = json.load(f)\n",
    "\n",
    "image_id = 0\n",
    "plt.clf()\n",
    "plt.close()\n",
    "\n",
    "# 対象イメージを特定\n",
    "for annotations_image in annotations_json['images']:\n",
    "    if annotations_image['file_name'] == FILE_NAME:\n",
    "        print(annotations_image)\n",
    "        image_id = annotations_image['id']\n",
    "\n",
    "image_np = np.array(Image.open(INPUT_IMAGE_FILE))\n",
    "# matplotlibで描画する\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = plt.axes()\n",
    "ax.imshow(image_np)\n",
    "# イメージに対するアノテーションを取得\n",
    "for annotations_row in annotations_json['annotations']:\n",
    "    if annotations_row['image_id'] == image_id:\n",
    "        # 検出した座標（左上を(0,0),右下を(1,1)とした相対座標)を取得\n",
    "        left, top, right, bot = annotations_row['bbox']\n",
    "         # 相対座標を絶対座標に変換する\n",
    "        x = left\n",
    "        w = right - left\n",
    "        y = bot\n",
    "        h = top - bot\n",
    "         # 検出した物体の ID を take/kino に読み替える\n",
    "        class_name = 'kino' if int(annotations_row['category_id'])==0 else 'take'\n",
    "         # take/kinoに対して矩形で描画するための色を設定する\n",
    "        color = 'blue' if class_name == 'take' else 'red'\n",
    "         # matplotlib に検出した物体に矩形を描画する\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=3, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        # 左上に検出結果と信頼度スコアを描画する\n",
    "        # ax.text(x, y, \"{} {:.0f}%\".format(class_name, 0), bbox=dict(facecolor='white', alpha=0.5))\n",
    "        ax.text(x, y, \"{}\".format(class_name), bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
